{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e47389f0",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[WinError 127] The specified procedure could not be found. Error loading \"C:\\Users\\samik\\Anaconda3\\lib\\site-packages\\torch\\lib\\c10_cuda.dll\" or one of its dependencies.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcollections\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m defaultdict\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# PyTorch\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# import torch.nn as nn\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# import torch.nn.functional as F\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# import torchvision.transforms as transforms\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     18\u001b[0m \n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# from torch import optim\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataLoader,Dataset\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\__init__.py:129\u001b[0m\n\u001b[0;32m    127\u001b[0m     err \u001b[38;5;241m=\u001b[39m ctypes\u001b[38;5;241m.\u001b[39mWinError(last_error)\n\u001b[0;32m    128\u001b[0m     err\u001b[38;5;241m.\u001b[39mstrerror \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m Error loading \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdll\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m or one of its dependencies.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m--> 129\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[0;32m    130\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m res \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    131\u001b[0m     is_loaded \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[1;31mOSError\u001b[0m: [WinError 127] The specified procedure could not be found. Error loading \"C:\\Users\\samik\\Anaconda3\\lib\\site-packages\\torch\\lib\\c10_cuda.dll\" or one of its dependencies."
     ]
    }
   ],
   "source": [
    "'''\n",
    "Adapated from: https://github.com/CVxTz/kinship_prediction/blob/master/code/vgg_face.py \n",
    "to parse the images and data\n",
    "This is NOT used to make the model! \n",
    "Additionally, this is run on a Windows OS. Some code may not be need if it is on a UNIX or LINUX OS. \n",
    "'''\n",
    "import pandas as pd\n",
    "from glob import glob #for finding files recursively \n",
    "from collections import defaultdict\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils\n",
    "import torchvision.datasets as dset\n",
    "\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "from torchvision.models import *\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.autograd import Variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380652b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "relationshipsCSV = \"./SMILE/train_relationships.csv\"\n",
    "train_images_folder = \"./SMILE/train/\"\n",
    "#what is the difference between train and train-face?\n",
    "val_set = \"F09\" #can change this, this is randomly generated \n",
    "'''\n",
    "Idea of hypertuning:\n",
    "using different validation sets for each iteration \n",
    "maybe instead of using only only family as the validation, we can use a group\n",
    "or change the validation set for each iteration of training the model \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2fa46b4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "availble_images = glob(train_images_folder + \"*/*/*.jpg\")\n",
    "'''\n",
    "Only for windows pc:\n",
    "'''\n",
    "for a in range(0, len(availble_images)):\n",
    "    availble_images[a] = availble_images[a].replace(\"\\\\\", \"/\")   \n",
    "    \n",
    "all_ppl = [x.split(\"/\")[-3] + \"/\" + x.split(\"/\")[-2] for x in availble_images] #all the people"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d24c3594",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the training set\n",
    "train_images = [x for x in availble_images if val_set not in x]\n",
    "train_person_to_images_map = defaultdict(list)\n",
    "for x in train_images:\n",
    "    train_person_to_images_map[x.split(\"/\")[-3] + \"/\" + x.split(\"/\")[-2]].append(x)\n",
    "\n",
    "#creating the validation set\n",
    "val_images = [x for x in availble_images if val_set in x]\n",
    "val_person_to_images_map = defaultdict(list)\n",
    "for x in val_images:\n",
    "    val_person_to_images_map[x.split(\"/\")[-3] + \"/\" + x.split(\"/\")[-2]].append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8aad46b3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'relationshipsCSV' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#read from the csv to create a list of tuples \u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m relationships \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[43mrelationshipsCSV\u001b[49m)\n\u001b[0;32m      3\u001b[0m relationship_pairs \u001b[38;5;241m=\u001b[39m [(row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mp1\u001b[39m\u001b[38;5;124m'\u001b[39m], row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mp2\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m index, row \u001b[38;5;129;01min\u001b[39;00m relationships\u001b[38;5;241m.\u001b[39miterrows()] \u001b[38;5;66;03m# Create a list of tuples\u001b[39;00m\n\u001b[0;32m      4\u001b[0m relationship_pairs \u001b[38;5;241m=\u001b[39m [x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m relationship_pairs \u001b[38;5;28;01mif\u001b[39;00m x[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m all_ppl \u001b[38;5;129;01mand\u001b[39;00m x[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m all_ppl]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'relationshipsCSV' is not defined"
     ]
    }
   ],
   "source": [
    "#read from the csv to create a list of tuples \n",
    "relationships = pd.read_csv(relationshipsCSV)\n",
    "relationship_pairs = [(row['p1'], row['p2']) for index, row in relationships.iterrows()] # Create a list of tuples\n",
    "relationship_pairs = [x for x in relationship_pairs if x[0] in all_ppl and x[1] in all_ppl] #data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "819da6b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the relationships taken from the csv into train and validation\n",
    "train = [x for x in relationship_pairs if val_set not in x[0]]\n",
    "val = [x for x in relationship_pairs if val_set in x[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2809c4ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nAdapted from: https://github.com/ale-mauro/Kinship-Recognition/blob/main/KinshipRecognition_Naive_DenseNet161_ResNet.ipynb\\nObtaining the training and validation set to use the following model:\\nhttps://keras.io/examples/vision/siamese_network/\\n\\nThe idea is to split to obtain a \"triple\" set:\\n1. an anchor\\n2. positive\\n3. negative\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Adapted from: https://github.com/ale-mauro/Kinship-Recognition/blob/main/KinshipRecognition_Naive_DenseNet161_ResNet.ipynb\n",
    "Obtaining the training and validation set to use the following model:\n",
    "https://keras.io/examples/vision/siamese_network/\n",
    "\n",
    "The idea is to split to obtain a \"triple\" set:\n",
    "1. an anchor\n",
    "2. positive\n",
    "3. negative\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8aaccc1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrandom\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mtrainingDataset\u001b[39;00m(\u001b[43mDataset\u001b[49m):\u001b[38;5;66;03m#Get two images and whether they are related.\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m#THIS PROCESS CAN BE OPTIMIZED BY CHOSING ALL THE TRAIN PAIRS AND THEN ADD SOME NEGATIVE SAMPLES\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \n\u001b[0;32m      6\u001b[0m     \u001b[38;5;66;03m# relationships will be the \"train\" (or \"val\") variable created above, so it contains the pairs of people who are related. \u001b[39;00m\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m,imageFolderDataset, relationships, transform\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m      8\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimageFolderDataset \u001b[38;5;241m=\u001b[39m imageFolderDataset    \n",
      "\u001b[1;31mNameError\u001b[0m: name 'Dataset' is not defined"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "class trainingDataset(Dataset):#Get two images and whether they are related.\n",
    "#THIS PROCESS CAN BE OPTIMIZED BY CHOSING ALL THE TRAIN PAIRS AND THEN ADD SOME NEGATIVE SAMPLES\n",
    "\n",
    "    # relationships will be the \"train\" (or \"val\") variable created above, so it contains the pairs of people who are related. \n",
    "    def __init__(self,imageFolderDataset, relationships, transform=None):\n",
    "        self.imageFolderDataset = imageFolderDataset    \n",
    "        self.relationships = relationships #choose either train or val dataset to use\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __getitem__(self,index):\n",
    "        # For each relationship in the \"train\" variable, the first image comes from first row, \n",
    "        # and the second is either specially choosed related person or randomly choosed non-related person (in order to have positive and negative samples)\n",
    "        img0_info = self.relationships[index][0]\n",
    "        img0_path = glob(\"train/\"+img0_info+\"/*.jpg\")\n",
    "        img0_path = random.choice(img0_path) #chose randomically a photo of the individual\n",
    "        \n",
    "        # Found all candidates related to person in img0\n",
    "        # candidate_relationship contains the value of self.relationship (that is the train or val variables,\n",
    "        # so candidate_relationship = (img0_info, 'Fxxx/MIDx') OR ('Fxxx/MIDx', img0_info))\n",
    "        candidate_relationship = [x for x in self.relationships if x[0]==img0_info or x[1]==img0_info] \n",
    "\n",
    "        # Randomly choose whether to use a positive (1) or a negative (0) example\n",
    "        if candidate_relationship==[]: # in this case, this should never happen.\n",
    "            choose_positive_example = 0\n",
    "        else:\n",
    "            # Choose randomicaly to have positive or negative example: 1 means related, and 0 means non-related.\n",
    "            choose_positive_example = random.randint(0,1) \n",
    "\n",
    "        # If we have to choose positive example, we get the second person from related relationship\n",
    "        if choose_positive_example==1:\n",
    "            img1_info = random.choice(candidate_relationship)#choose the second person from related relationships\n",
    "            # remember that candidate_relationship = (img0_info, 'Fxxx/MIDx') OR ('Fxxx/MIDx', img0_info)),\n",
    "            # so img1 is the element of the tuple that is not img0_info \n",
    "            if img1_info[0] != img0_info:\n",
    "                img1_info = img1_info[0]\n",
    "            else:\n",
    "                img1_info=img1_info[1]\n",
    "\n",
    "            #randomly choose a img of second person\n",
    "            img1_path = glob(\"train/\"+img1_info+\"/*.jpg\")\n",
    "            img1_path = random.choice(img1_path)\n",
    "\n",
    "        # In case we have to choose negative sample, we get the second person randomicaly (0 means non-related)\n",
    "        else:\n",
    "            randChoose = True #in case the random chosen person is related to first person\n",
    "            while randChoose:\n",
    "                img1_path = random.choice(self.imageFolderDataset.imgs)[0]\n",
    "                img1_info = img1_path.split(\"/\")[-3] + \"/\" + img1_path.split(\"/\")[-2]\n",
    "                randChoose = False\n",
    "                #if we (unforunatly) choose a person who is related to the first one, randomly choose another person\n",
    "                for x in candidate_relationship:\n",
    "                    if x[0]==img1_info or x[1]==img1_info:\n",
    "                        randChoose = True\n",
    "                        break\n",
    "\n",
    "        # Now we have two images (they are related or not)\n",
    "        img0 = Image.open(img0_path)\n",
    "        img1 = Image.open(img1_path)\n",
    "        \n",
    "        # Transform images\n",
    "        if self.transform is not None:\n",
    "            img0 = self.transform(img0)\n",
    "            img1 = self.transform(img1)\n",
    "        \n",
    "        # The returned data from dataloader is img=[batch_size,channels,width,length], should_get_same_class=[batch_size,label]\n",
    "        return img0, img1 , choose_positive_example \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.relationships)#essential for choose the num of data in one epoch\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f97c167",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_dataset = dset.ImageFolder(root='train/')\n",
    "BATCH_SIZE=64\n",
    "IMG_SIZE=100\n",
    "\n",
    "#Training set and training loader\n",
    "trainset = trainingDataset(imageFolderDataset=folder_dataset,\n",
    "                                        relationships=train,\n",
    "                                        transform=transforms.Compose([transforms.Resize((IMG_SIZE,IMG_SIZE)),\n",
    "                                                                      transforms.ToTensor()\n",
    "                                                                      ]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
